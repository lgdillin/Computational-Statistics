\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Problem 1}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Problem 2}{2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Write out the ridge regression optimization problem in this setting}{2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Argue that in this setting, the ridge coefficient estimates satisfy $\mathaccentV {hat}05E{\beta _1} = \mathaccentV {hat}05E{\beta _2}$.}{3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Write out the lasso optimzation problem in this setting.}{4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Argue that in this setting, the lasso coefficients $\mathaccentV {hat}05E{\beta _1}$ and $\mathaccentV {hat}05E{\beta _2}$ are not unique - in other words, there are many possible solutions to the optimization problem in $(3)$. Describe these solutions.}{5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Problem 3}{5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Prove the full conditional distributions of $\theta $ and $\sigma ^{2}$}{5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Using the normal model above, implement the gibbs sampler}{6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Plot histograms of $\qopname  \relax o{log}(\theta )$ and $\qopname  \relax o{log}(\sigma ^{2})$ and report $90\%$ posterior probability intervals for both}{7}\protected@file@percent }
